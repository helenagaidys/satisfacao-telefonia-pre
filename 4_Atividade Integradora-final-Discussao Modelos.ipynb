{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atividade Integradora\n",
    "\n",
    "### Discussão dos Modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Autores:\n",
    "#### Helena Boin Gaidys\n",
    "#### Luiz Gustavo Mauro Cardoso\n",
    "#### Nanci Utida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussão da Modelagem\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descrição do Método\n",
    "\n",
    "O objetivo deste trabalho foi desenvolver e comparar modelos preditivos  utilizando diferentes métodos (abordados na disciplina de Modelos Preditivos). Os dados utilizados foram da base de dados da pesquisa da Anatel. A limpeza e preparação da base de dados foi realizada no Python e as variáveis preditoras foram selecionadas para melhor ajuste dos modelos. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![TABELA](img/base_dados.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Satisfação Geral\n",
    "\n",
    "Foi perguntado o nível de satisfação geral do entrevistado com a prestadora citada, levando em conta toda a experiência com esta. \n",
    "O entrevistado deveria dar uma nota de zero (totalmente insatisfeito) a dez (totalmente satisfeito).\n",
    "\n",
    "Na análise deste trabalho, consideramos notas iguais ou maiores que 8 como \"Satisfação Alta\" e notas menores que 8 como \"Satisfação Baixa\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![SATISFACAO](img/graph_satisf_geral.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Satisfação vs. Oferta e Contratação\n",
    "\n",
    "##### Facilidade de entendimento\n",
    "\n",
    "Nota atribuída com respeito à facilidade de entendimento dos planos e serviços contratados tem correlação direta com a satisfação global do usuário com a operadora do plano de telefonia.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "![FACIL_ENTEND](img/graph_facil_entend.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Satisfação vs. Oferta e Contratação\n",
    "\n",
    "##### Comprometimento\n",
    "\n",
    "Nota atribuída com respeito ao comprometimento da operadora em cumprir o que foi prometido e divulgado em sua publicidade também tem correlação direta com a satisfação global.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "![CUMPR_PROMETIDO](img/graph_cumpr_prometido.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos Preditivos (R)\n",
    "\n",
    "O objetivo desta modelagem preditiva foi criar modelos com\n",
    "informações da pesquisa para prever a satisfação do usuário. Para este fim, testamos os modelos de Regressão Logística, Ridge, Lasso, Random Forest, Boosting e Bagging.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparação entre os Modelos\n",
    "\n",
    "Utilizamos o Erro Médio de Previsão neste trabalho como uma medida de qualidade de previsão do modelo ajustado aos dados. \n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "erro <- mean(df_test$satisfacao != pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizamos também o parâmetro \"Acurácia\" da precisão preditiva (matriz de confusão), através do pacote \"caret\".\n",
    "\n",
    "Esta medida  foi o principal critério de escolha utilizado para definir o melhor modelo  utilizado para cumprir o objetivo geral deste trabalho. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "confusionMatrix(resultados$predito, resultados$observado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "###   Método               (erro)      [acurácia]\n",
    "#### 1 Random Forest    (0.197)    [80.30%]\n",
    "#### 2 Bagging             (0.208)          [79.15%]\n",
    "#### 3 Regressão Logística (0.209) [79.06%]\n",
    "#### 4 Lasso               (0.210)            [79.04%]\n",
    "#### 5 Boosting            (0.225)           [77.49%]\n",
    "#### 6 Ridge               (0.229)             [77.10%]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Random Forest\n",
    "Floresta Aleatória (Random Forest) foi o método que teve o menor erro médio e maior acurácia em nossas simulações. O uso de Random Forests evita a ocorrência de overfit. É um método de aprendizagem de máquina versátil e capaz de executar tarefas de regressão e de classificação; aplica métodos de redução dimensional, trata valores faltantes e ‘outliers’."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " \n",
    " Call:\n",
    "  randomForest(formula = satisfacao ~ ., data = df_train) \n",
    "                Type of random forest: classification\n",
    "                      Number of trees: 500\n",
    " No. of variables tried at each split: 5\n",
    " \n",
    "         OOB estimate of  error rate: 19.99%\n",
    "Confusion matrix:\n",
    "       Baixo  Alto class.error\n",
    " Baixo 43233 14193   0.2471529\n",
    " Alto   9438 51362   0.1552303"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de Confusão e Acurácia Preditiva"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "> CM_RF\n",
    "Confusion Matrix and Statistics\n",
    "\n",
    "          Reference\n",
    "Prediction Baixo  Alto\n",
    "     Baixo 10903  2307\n",
    "     Alto   3517 12830\n",
    "                                          \n",
    "               Accuracy : 0.803           \n",
    "                 95% CI : (0.7984, 0.8075)\n",
    "    No Information Rate : 0.5121          \n",
    "    P-Value [Acc > NIR] : < 2.2e-16       \n",
    "                                          \n",
    "                  Kappa : 0.6049          \n",
    "                                          \n",
    " Mcnemar's Test P-Value : < 2.2e-16       \n",
    "                                          \n",
    "            Sensitivity : 0.7561          \n",
    "            Specificity : 0.8476          \n",
    "         Pos Pred Value : 0.8254          \n",
    "         Neg Pred Value : 0.7849          \n",
    "             Prevalence : 0.4879          \n",
    "         Detection Rate : 0.3689          \n",
    "   Detection Prevalence : 0.4469          \n",
    "      Balanced Accuracy : 0.8018          \n",
    "                                          \n",
    "       'Positive' Class : Baixo  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importância das Variáveis\n",
    "![RF](img/Random_Forest.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O algoritmo considerou as seguintes variáveis de maior importância (10 primeiros):<p>\n",
    "1) Estado<p>\n",
    "2) Cumprir o que foi prometido<p>\n",
    "3) Facilidade de Entendimento (planos e contratação) <p>\n",
    "4) Fazer e Receber Ligações<p>\n",
    "5) Idade<p>\n",
    "6) Clareza da Conta<p>\n",
    "7) Cobrança Correta <p>\n",
    "8) Operadora<p>\n",
    "9) Residentes (Quantidade de pessoas residentes que contribuem com a renda total do domicílio) <p>\n",
    "10) Qualidade da Ligação \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest emprega várias técnicas para reduzir a variância nas previsões, mantendo (até certo ponto) a baixa variância que era característica da única Árvore de Decisão. Isso é feito principalmente pela média de várias árvores muito fracamente correlacionadas (se não completamente não correlacionadas)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Bagging\n",
    "\n",
    "Bagging (bootstrap aggregating) é um meta-algoritmo (usado em machine learning) desenvolvido para melhorar a estabilidade e a precisão dos algoritmos usados na classificação e regressão estatística. Reduz a variância e ajuda a evitar overfitting. \n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Bagging classification trees with 25 bootstrap replications \n",
    "\n",
    "Call: bagging.data.frame(formula = satisfacao ~ ., data = df_train, \n",
    "    coob = TRUE)\n",
    "\n",
    "Out-of-bag estimate of misclassification error:  0.2235 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de Confusão e Acurácia Preditiva"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "> CM_Bag\n",
    "Confusion Matrix and Statistics\n",
    "\n",
    "          Reference\n",
    "Prediction Baixo  Alto\n",
    "     Baixo 11325  3068\n",
    "     Alto   3095 12069\n",
    "                                          \n",
    "               Accuracy : 0.7915          \n",
    "                 95% CI : (0.7868, 0.7961)\n",
    "    No Information Rate : 0.5121          \n",
    "    P-Value [Acc > NIR] : <2e-16          \n",
    "                                          \n",
    "                  Kappa : 0.5827          \n",
    "                                          \n",
    " Mcnemar's Test P-Value : 0.7405          \n",
    "                                          \n",
    "            Sensitivity : 0.7854          \n",
    "            Specificity : 0.7973          \n",
    "         Pos Pred Value : 0.7868          \n",
    "         Neg Pred Value : 0.7959          \n",
    "             Prevalence : 0.4879          \n",
    "         Detection Rate : 0.3832          \n",
    "   Detection Prevalence : 0.4870          \n",
    "      Balanced Accuracy : 0.7913          \n",
    "                                          \n",
    "       'Positive' Class : Baixo "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No caso do Bagging, as múltiplas árvores geradas pelos múltiplos processos de bootstrap não são submetidas à poda. Isso quer dizer que crescem sem limitações e por isso todas possuem overfitting. Dessa forma, cada árvore individualmente possui elevada variância nos estimadores, mas baixo viés."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Regressão Logística\n",
    "\n",
    "A regressão logística é uma técnica estatística que tem como objetivo produzir, a partir de um conjunto de observações, um modelo que permita a predição de valores tomados por uma variável categórica, frequentemente binária, a partir de uma série de variáveis explicativas contínuas e/ou binárias."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " Call:\n",
    " glm(formula = satisfacao ~ ., family = \"binomial\", data = df_train)\n",
    " \n",
    " Deviance Residuals: \n",
    "     Min       1Q   Median       3Q      Max  \n",
    " -2.7415  -0.6049   0.2805   0.5903   2.9162  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de Confusão e Acurácia Preditiva"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "> CM_Log\n",
    "Confusion Matrix and Statistics\n",
    "\n",
    "          Reference\n",
    "Prediction Baixo  Alto\n",
    "     Baixo 12746  4515\n",
    "     Alto   1674 10622\n",
    "                                          \n",
    "               Accuracy : 0.7906          \n",
    "                 95% CI : (0.7859, 0.7952)\n",
    "    No Information Rate : 0.5121          \n",
    "    P-Value [Acc > NIR] : < 2.2e-16       \n",
    "                                          \n",
    "                  Kappa : 0.5829          \n",
    "                                          \n",
    " Mcnemar's Test P-Value : < 2.2e-16       \n",
    "                                          \n",
    "            Sensitivity : 0.8839          \n",
    "            Specificity : 0.7017          \n",
    "         Pos Pred Value : 0.7384          \n",
    "         Neg Pred Value : 0.8639          \n",
    "             Prevalence : 0.4879          \n",
    "         Detection Rate : 0.4312          \n",
    "   Detection Prevalence : 0.5840          \n",
    "      Balanced Accuracy : 0.7928          \n",
    "                                          \n",
    "       'Positive' Class : Baixo  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### O modelo de regressão logística selecionou as principais variáveis que melhor explicam a satisfação do usuário. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Coefficients: \n",
    "#                              Estimate Std. Error z value Pr(>|z|)    \n",
    "# ESTADODF                   -0.1978455  0.0606128  -3.264 0.001098 ** \n",
    "# ESTADOGO                   -0.1160126  0.0579724  -2.001 0.045374 *   \n",
    "# ESTADOMG                   -0.2269824  0.0583299  -3.891 9.97e-05 *** \n",
    "# ESTADOPB                    0.1696375  0.0603222   2.812 0.004921 *   \n",
    "# ESTADOPR                   -0.1821043  0.0601345  -3.028 0.002459 ** \n",
    "# ESTADORR                   -0.1929714  0.0610268  -3.162 0.001566 ** \n",
    "# ESTADORS                   -0.1787022  0.0605468  -2.951 0.003163 ** \n",
    "# sexoMasculino              -0.1837201  0.0162692 -11.293  < 2e-16 ***\n",
    "# facil_entendBaixo          -0.4650033  0.0894730  -5.197 2.02e-07 ***\n",
    "# facil_entendAlto            0.4131728  0.0895461   4.614 3.95e-06 ***\n",
    "# cumpr_prometidoBaixo       -0.3482273  0.0766409  -4.544 5.53e-06 ***\n",
    "# cumpr_prometidoAlto         0.8329189  0.0767359  10.854  < 2e-16 *** \n",
    "# fzr_rcbr_ligAlto            0.8010041  0.2268342   3.531 0.000414 ***\n",
    "# acesso_internetAlto         0.8778347  0.2634691   3.332 0.000863 *** \n",
    "# cobranca_corretaAlto        0.2100456  0.1036478   2.027 0.042710 *  \n",
    "# clareza_contaBaixo         -0.3701620  0.1236342  -2.994 0.002753 **  \n",
    "# espera_atendBaixo          -0.4654428  0.1876046  -2.481 0.013102 *  \n",
    "# espera_atendAlto           -0.3929445  0.1880846  -2.089 0.036691 *    \n",
    "# quali_atend_internetNão     0.4289668  0.1634763   2.624 0.008690 ** \n",
    "# quali_atend_internetBaixo   0.3872861  0.1653606   2.342 0.019177 *  \n",
    "# quali_atend_internetAlto    0.5446530  0.1649817   3.301 0.000962 ***\n",
    "# quali_atend_lojaAlto        0.5455244  0.2277397   2.395 0.016603 *  \n",
    "# res_prob_cobrancaNão        1.6838279  0.5172383   3.255 0.001132 ** \n",
    "# res_prob_cobrancaBaixo      1.4317666  0.5175707   2.766 0.005669 ** \n",
    "# res_prob_cobrancaAlto       1.6054893  0.5177429   3.101 0.001929 ** \n",
    "# res_prob_internetNão        1.2644480  0.5251672   2.408 0.016053 *   \n",
    "# res_prob_internetAlto       1.2964100  0.5264031   2.463 0.013787 *  \n",
    "# servico_concNão             0.2361658  0.0322186   7.330 2.30e-13 ***\n",
    "# servico_concSim            -0.1314755  0.0278655  -4.718 2.38e-06 ***\n",
    "# residentes                  0.0278355  0.0064868   4.291 1.78e-05 ***\n",
    "# salariode 4 a 6 SM         -0.1610857  0.0416392  -3.869 0.000109 ***\n",
    "# salariode 6 a 10 SM        -0.1280775  0.0523802  -2.445 0.014479 *  \n",
    "# salarioacima de 10 SM      -0.2320218  0.0847447  -2.738 0.006183 ** \n",
    "# faixa_idadeDe 25 a 30 anos  0.0808032  0.0258497   3.126 0.001773 ** \n",
    "# faixa_idadeDe 31 a 35 anos  0.1636178  0.0280675   5.829 5.56e-09 ***\n",
    "# faixa_idadeDe 36 a 40 anos  0.2307858  0.0289134   7.982 1.44e-15 ***\n",
    "# faixa_idadeDe 41 a 50 anos  0.2897417  0.0271342  10.678  < 2e-16 ***\n",
    "# faixa_idadeDe 51 a 70 anos  0.3301200  0.0299133  11.036  < 2e-16 ***\n",
    "# faixa_idadeMais de 70 anos  0.4140117  0.0849237   4.875 1.09e-06 ***\n",
    "# ---\n",
    "\n",
    "# Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " (Dispersion parameter for binomial family taken to be 1)\n",
    " \n",
    "     Null deviance: 163800  on 118225  degrees of freedom\n",
    " Residual deviance: 100522  on 118132  degrees of freedom\n",
    " AIC: 100710\n",
    " \n",
    " Number of Fisher Scoring iterations: 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) LASSO (Least Absolute Shrinkage and Selection Operator)\n",
    "O LASSO tem um mecanismo de penalização dos coeficientes com um alto grau de correlação entre si, mas que usa o mecanismo de penalizar os coeficientes de acordo com o seu valor absoluto (soma dos valores dos estimadores) usando o mecanismo de minimizar o erro quadrático. Isso é feito através da penalização do coeficiente até que o mesmo convirja para zero; o que naturalmente vai eliminar o atributo e reduzir a dimensionalidade do modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![LassoL](img/lasso_lamb.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lambda LASSO\n",
    "\n",
    "Utilizamos validação cruzada para determinar o valor ótimo de Lambda. Esse gráfico abaixo apresentam a estimativa do erro e o desvio-padrão.\n",
    "\n",
    "![Lasso](img/lasso.png)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Call:  glmnet::cv.glmnet(x = x[treino, ], y = y[treino], alpha = 1,      family = \"binomial\") \n",
    "\n",
    "Measure: Binomial Deviance \n",
    "\n",
    "      Lambda Measure       SE Nonzero\n",
    "min 0.000405  0.8519 0.003905      77\n",
    "1se 0.004990  0.8554 0.003627      40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de Confusão e Acurácia Preditiva"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "> CM_Lasso\n",
    "Confusion Matrix and Statistics\n",
    "\n",
    "          Reference\n",
    "Prediction Baixo  Alto\n",
    "     Baixo 12743  4517\n",
    "     Alto   1677 10620\n",
    "                                          \n",
    "               Accuracy : 0.7904          \n",
    "                 95% CI : (0.7858, 0.7951)\n",
    "    No Information Rate : 0.5121          \n",
    "    P-Value [Acc > NIR] : < 2.2e-16       \n",
    "                                          \n",
    "                  Kappa : 0.5826          \n",
    "                                          \n",
    " Mcnemar's Test P-Value : < 2.2e-16       \n",
    "                                          \n",
    "            Sensitivity : 0.8837          \n",
    "            Specificity : 0.7016          \n",
    "         Pos Pred Value : 0.7383          \n",
    "         Neg Pred Value : 0.8636          \n",
    "             Prevalence : 0.4879          \n",
    "         Detection Rate : 0.4311          \n",
    "   Detection Prevalence : 0.5840          \n",
    "      Balanced Accuracy : 0.7926          \n",
    "                                          \n",
    "       'Positive' Class : Baixo   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Boosting\n",
    "\n",
    "É uma técnica que combina diversos classificadores fracos com o objetivo de melhorar a acurácia geral. Em cada iteração, o algoritmo atualiza os pesos dos exemplos e constrói um classificador adicional. O modelo tenta reduzir o erro nas previsões, concentrando-se nas previsões ruins e modelá-las melhor na próxima iteração e, portanto, reduz o viés.\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " gbm(formula = satisfacao ~ ., distribution = \"bernoulli\", data = dados_tr, \n",
    "     n.trees = 1000, interaction.depth = 4, shrinkage = 0.05)\n",
    " A gradient boosted model with bernoulli loss function.\n",
    " 1000 iterations were performed.\n",
    " There were 28 predictors of which 28 had non-zero influence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### O método usa a validação cruzada (cv-cross validation), para encontrar o melhor modelo. \n",
    "\n",
    "![boost](img/boosting_cv.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de Confusão e Acurácia Preditiva"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "> CM_Boost\n",
    "Confusion Matrix and Statistics\n",
    "\n",
    "          Reference\n",
    "Prediction Baixo  Alto\n",
    "     Baixo 13247  5479\n",
    "     Alto   1173  9658\n",
    "                                          \n",
    "               Accuracy : 0.7749          \n",
    "                 95% CI : (0.7701, 0.7797)\n",
    "    No Information Rate : 0.5121          \n",
    "    P-Value [Acc > NIR] : < 2.2e-16       \n",
    "                                          \n",
    "                  Kappa : 0.5528          \n",
    "                                          \n",
    " Mcnemar's Test P-Value : < 2.2e-16       \n",
    "                                          \n",
    "            Sensitivity : 0.9187          \n",
    "            Specificity : 0.6380          \n",
    "         Pos Pred Value : 0.7074          \n",
    "         Neg Pred Value : 0.8917          \n",
    "             Prevalence : 0.4879          \n",
    "         Detection Rate : 0.4482          \n",
    "   Detection Prevalence : 0.6336          \n",
    "      Balanced Accuracy : 0.7783          \n",
    "                                          \n",
    "       'Positive' Class : Baixo  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Influência relativa das variáveis"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "cumpr_prometido           cumpr_prometido 49.10994286\n",
    "facil_entend                 facil_entend 16.21443278\n",
    "fzr_rcbr_lig                 fzr_rcbr_lig  9.66243925\n",
    "clareza_conta               clareza_conta  4.96730486\n",
    "cobranca_correta         cobranca_correta  3.45646029\n",
    "quali_lig                       quali_lig  2.83251204\n",
    "ESTADO                             ESTADO  2.69339214\n",
    "acesso_internet           acesso_internet  2.32315916\n",
    "quali_atend_tel           quali_atend_tel  1.77057943\n",
    "manter_conex                 manter_conex  1.18954208\n",
    "veloc_internet             veloc_internet  0.93917795\n",
    "val_recarga                   val_recarga  0.68611047\n",
    "faixa_idade                   faixa_idade  0.57828275\n",
    "res_prob_cobranca       res_prob_cobranca  0.52925069\n",
    "servico_conc                 servico_conc  0.49837115\n",
    "res_prob_internet       res_prob_internet  0.47197310\n",
    "repetir_demanda           repetir_demanda  0.34234733\n",
    "OPERADORA                       OPERADORA  0.26240549\n",
    "sexo                                 sexo  0.20931555\n",
    "quali_atend_internet quali_atend_internet  0.20671890\n",
    "res_prob_lig                 res_prob_lig  0.19779352\n",
    "residentes                     residentes  0.19106637\n",
    "clareza_atend               clareza_atend  0.14960316\n",
    "salario                           salario  0.13167329\n",
    "quali_atend_loja         quali_atend_loja  0.12965109\n",
    "espera_atend                 espera_atend  0.11993636\n",
    "ANO_BASE                         ANO_BASE  0.11898733\n",
    "responsavel_recarga   responsavel_recarga  0.01757061"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O algoritmo considerou as seguintes variáveis de maior importância (10 primeiros):<p>\n",
    "1) Cumprir o que foi prometido<p>\n",
    "    \n",
    "2) Facilidade de Entendimento (planos e contratação) <p>\n",
    "3) Fazer e Receber Ligações<p>\n",
    "4) Clareza da Conta<p>\n",
    "5) Cobrança Correta <p>\n",
    "6) Qualidade da Ligação <p>\n",
    "7) Estado<p>\n",
    "8) Acesso à Internet<p>\n",
    "9) Qualidade do Atendimento Telefônico <p>\n",
    "10) Capacidade de manter a conexão (3G/4G) sem quedas\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) Ridge\n",
    "\n",
    " Ridge é um método de regularização do modelo que tem como principal objetivo suavizar atributos que sejam relacionados uns aos outros e que aumentam a multicolinearidade. Com isso com a retirada de determinados atributos do modelo, o mesmo converge para um resultado muito mais estável em que com a redução desses atributos, a redução em termos de acuácia do modelo se mantêm inalterada. O algoritmo é através de um mecanismo de penalização que coloca um viés e que vai reduzindo os valores os betas até não zero. Com isso os atributos que contribuem menos para o poder preditivo do modelo são levados para a irrelevância usando esse mecanismo de penalização do viés."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ridge](img/ridge_lamb.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lambda Ridge\n",
    "\n",
    "Utilizamos validação cruzada para determinar o valor ótimo de Lambda. Esse gráfico abaixo apresentam a estimativa do erro e o desvio-padrão.\n",
    "\n",
    "![Ridg](img/ridge.png)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Call:  glmnet::cv.glmnet(x = x[treino, ], y = y[treino], alpha = 0,      family = \"binomial\") \n",
    "\n",
    "Measure: Binomial Deviance \n",
    "\n",
    "     Lambda Measure       SE Nonzero\n",
    "min 0.02726  0.8527 0.003764      99\n",
    "1se 0.07584  0.8563 0.003473      99"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matriz de Confusão e Acurácia Preditiva"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "> CM_Ridge\n",
    "Confusion Matrix and Statistics\n",
    "\n",
    "          Reference\n",
    "Prediction Baixo  Alto\n",
    "     Baixo 13287  5636\n",
    "     Alto   1133  9501\n",
    "                                          \n",
    "               Accuracy : 0.771           \n",
    "                 95% CI : (0.7662, 0.7758)\n",
    "    No Information Rate : 0.5121          \n",
    "    P-Value [Acc > NIR] : < 2.2e-16       \n",
    "                                          \n",
    "                  Kappa : 0.5451          \n",
    "                                          \n",
    " Mcnemar's Test P-Value : < 2.2e-16       \n",
    "                                          \n",
    "            Sensitivity : 0.9214          \n",
    "            Specificity : 0.6277          \n",
    "         Pos Pred Value : 0.7022          \n",
    "         Neg Pred Value : 0.8935          \n",
    "             Prevalence : 0.4879          \n",
    "         Detection Rate : 0.4495          \n",
    "   Detection Prevalence : 0.6402          \n",
    "      Balanced Accuracy : 0.7745          \n",
    "                                          \n",
    "       'Positive' Class : Baixo "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusões finais\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No presente estudo foram aplicados seis métodos para modelagem. \n",
    "\n",
    "O melhor método em predição foi a **Floresta Aleatória (Random Forest)**, seguida do método **Bagging** (bootstrap aggregating) e em terceiro lugar a **Regressão Logística**.\n",
    "\n",
    "As principais vantagens do **Random Forest** incluem sua natureza não paramétrica, sua alta precisão preditiva e a capacidade de determinar a importância da variável. \n",
    "\n",
    "A importância das variáveis é interessante para entender melhor o papel individual e o efeito combinado de variáveis explicativas em um modelo preditivo. \n",
    "\n",
    "O método **Bagging** consiste em combinar duas técnicas chaves,\n",
    "o bootstrap e a agregação e combina vários modelos preditivos. Mas o  ganho de acurácia do Bagging tem o custo da perda de visualização\n",
    "do modelo.\n",
    "\n",
    "A **Regressão Logística** é uma técnica amplamente empregada. No nosso estudo, teve um bom poder preditivo, porém inferior ao Bagging e Random Forest. Entretanto, apesar do desempenho inferior aos dois primeiros modelos, a Regressão Logística é  útil para expressar a relação entre uma variável dependente (resposta) dicotômica e uma ou mais variáveis independentes, que podem ser quantitativas ou categóricas, pois permite estimar a magnitude e a direção dos efeitos preditores.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
